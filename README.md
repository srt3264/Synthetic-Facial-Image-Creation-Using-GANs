# Emotion Recognition from Facial Images using CNN and ResNet50 models
This project aims to build and evaluate convolutional neural network (CNN) and ResNet50 models for recognizing emotions from facial images, using the seven emotional categories from the FER2013 dataset. The 'disgust' category is imbalanced, so we create synthetic images to balance the data. We first train a baseline CNN and a baseline ResNet50 model. Then, we use a stylistic GAN and a DCgan to separately prepare 4,000 images for the 'disgust' category. Finally, we use the 4,000 images from each GAN to retrain the two models separately and evaluate their performance.

## Dataset
The dataset used in this project is the FER2013 dataset, which contains 35,887 grayscale images of size 48x48 pixels, with seven emotional categories: anger, disgust, fear, happiness, sadness, surprise, and neutral. The dataset is divided into training, validation, and test sets, with respective sizes of 28,709, 3,589, and 3,589. We balance the 'disgust' category by creating synthetic images using two different GAN models.

## Models
We build two different models for emotion recognition: a CNN and a ResNet50. The CNN consists of several convolutional and pooling layers, followed by fully connected layers and a softmax output layer. The ResNet50 is a deep residual network architecture that can learn more complex features than a traditional CNN, using skip connections that allow for better gradient flow during training. 

The resnet50 model can be found at '''Team-8-Machine-Learning/Classification_models/classification_model/resnet_final-base.ipynb'''
The CNN model can be found at '''Team-8-Machine-Learning/Classification_models/'''

We train the baseline CNN and ResNet50 models on the original training set, and evaluate their performance on the validation and test sets. Then, we separately use a stylistic GAN and a DCgan to generate 4,000 synthetic images for the 'disgust' category. We train the two models separately on the combined original and synthetic data, and evaluate their performance on the same validation and test sets.

The code for retraining the RESNET model can be found at: 
'''Team-8-Machine-Learning/Classification_models/classification_model/resnet_final style.ipynb'''
'''Team-8-Machine-Learning/Classification_models/classification_model/resnet_final dc.ipynb'''

The code for retraining the CNN model can be found at: 


Below is a diagram of the expetimental design. 
![Data](https://user-images.githubusercontent.com/110945807/233225312-4f75e4c4-0dfe-436c-a06b-3f2454d66d71.png)



## Results
The baseline CNN and ResNet50 models achieve a validation accuracy of around 60-65% and a test accuracy of around 57-60%. After adding the synthetic images generated by the GAN models, the performance of both models improves significantly, with validation accuracies of around 72-76% and test accuracies of around 68-71%.

Usage


## Acknowledgments
This project was inspired by the FER2013 dataset and the work of several researchers in the field of emotion recognition from facial images. We thank the authors of the GAN models used for generating synthetic images, and the open-source community for providing resources and tools for deep learning research.
