{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 65% accuracy on test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train model\n",
    "# resnet18\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Variables\n",
    "train_folder = 'train'\n",
    "val_folder = 'test'\n",
    "num_classes = 7\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "\n",
    "# Data augmentation\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "train_dataset = ImageFolder(train_folder, transform=data_transforms)\n",
    "val_dataset = ImageFolder(val_folder, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Load pre-trained MobileNetV2\n",
    "resnet18_base = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze the last layer\n",
    "num_ftrs = resnet18_base.fc.in_features\n",
    "resnet18_base.fc = nn.Identity()\n",
    "\n",
    "# Custom top layers\n",
    "output_layer = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, num_classes),\n",
    ")\n",
    "resnet18_base.add_module('output', output_layer)\n",
    "\n",
    "# Define the criterion, optimizer, and device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet18_base.parameters(), lr=0.001, momentum=0.9)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train the model\n",
    "resnet18_base.train()\n",
    "resnet18_base.to(device)\n",
    "\n",
    "\n",
    "# Initialize best validation loss and model saving path\n",
    "best_val_loss = float('inf')\n",
    "model_save_path = 'best_model_res.pth'\n",
    "\n",
    "# Train and validate the model\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    resnet18_base.train()\n",
    "    running_train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet18_base(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    # Validate\n",
    "    resnet18_base.eval()\n",
    "    running_val_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet18_base(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # Calculate average accuracies\n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    avg_val_loss = running_val_loss / len(val_loader)\n",
    "    epoch_acc = running_corrects.double() / len(val_dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}, Val Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Save the best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(resnet18_base.state_dict(), model_save_path)\n",
    "        print(\"Best validation loss improved. Model saved.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Identity()\n",
    "    \n",
    "    # Custom top layers\n",
    "    output_layer = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 7),\n",
    "    )\n",
    "    model.add_module('output', output_layer)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    return input_batch\n",
    "\n",
    "def predict_emotion(model, input_batch):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_batch = input_batch.to(device)\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        _, predicted_emotion = torch.max(output, 1)\n",
    "    return predicted_emotion.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and predict the emotion for an image\n",
    "model_path = 'best_model_res.pth'\n",
    "image_path = 'archive/train/angry/Training_3908.jpg'\n",
    "model = load_model(model_path)\n",
    "input_batch = preprocess_image(image_path)\n",
    "predicted_emotion = predict_emotion(model, input_batch)\n",
    "\n",
    "print(\"Predicted emotion:\", predicted_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to map the predicted emotion to the actual emotion\n",
    "dict_emo = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', 4: 'neutral', 5: 'sad', 6: 'surprise'}\n",
    "print(\"Predicted emotion:\", dict_emo[predicted_emotion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchviz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torchviz import make_dot\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Identity()\n",
    "    \n",
    "    # Custom top layers\n",
    "    output_layer = nn.Sequential(\n",
    "        nn.Linear(num_ftrs, 7),\n",
    "    )\n",
    "    model.add_module('output', output_layer)\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'best_model_res.pth'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Generate a random input tensor\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Get the output of the model\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Visualize the model's architecture\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "\n",
    "# Save the visualization as an image\n",
    "dot.format = 'png'\n",
    "dot.render('loaded_model_architecture')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
